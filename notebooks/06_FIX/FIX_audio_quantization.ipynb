{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1 \n",
      "Sample width: 2 bytes\n",
      "Sample rate: 11025\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required for the axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d99db429966a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mdata_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchararray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_out\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# convert back to string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;31m#    data_out = wf.readframes(CHUNK) # direct streaming without numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msamp_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required for the axis"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "=== FIX_pyaudio_quantization.py ============================================\n",
    "\n",
    "Demonstrate quantization effects with audio signals:\n",
    "\n",
    "Read an audio file frame by frame, quantize the samples and stream the data\n",
    "to an audio device via pyaudio.\n",
    " \n",
    "===========================================================================\n",
    "\"\"\"\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from numpy import (pi, log10, exp, sqrt, sin, cos, tan, angle, arange,\n",
    "                    linspace, array, zeros, ones)\n",
    "from numpy.fft import fft, ifft, fftshift, ifftshift, fftfreq\n",
    "import scipy.signal as sig\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import (figure, plot, stem, grid, xlabel, ylabel,\n",
    "    subplot, title, clf, xlim, ylim)\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import dsp_fpga_fix_lib as fx\n",
    "\n",
    "import wave\n",
    "import os\n",
    "\n",
    "np_type = np.int16 # format of audio samples\n",
    "CHUNK = 1024 # number of stereo samples per frame\n",
    "\n",
    "path = '../medien/'\n",
    "\n",
    "#filename = 'chord.wav'\n",
    "#filename = '07 - Danny Gottlieb with John McLaughlin - Duet.wav'\n",
    "#filename = 'Ole_16bit.wav'\n",
    "#filename = '01 - Santogold - L.E.S Artistes.wav'\n",
    "filename = 'SpaceRipple.wav'\n",
    "\n",
    "wf = wave.open(os.path.join(path, filename))\n",
    "n_chan = wf.getnchannels() # number of channels in wav-file\n",
    "w_samp = wf.getsampwidth() # wordlength of samples\n",
    "samp_rate = wf.getframerate() # samplerate in wav-file\n",
    "\n",
    "print(\"Channels:\", n_chan, \"\\nSample width:\",w_samp,\n",
    "      \"bytes\\nSample rate:\",samp_rate)\n",
    "\n",
    "# Define quantization mode and create a quantization instance for each channel\n",
    "# quantize with just a few bits:\n",
    "q_obj = {'Q':-2.15,'quant':'round','ovfl':'sat'} # try 'quant':'round', 'ovfl':'sat'\n",
    "\n",
    "# Overflows QI = -1 means the MSB is 2^{-1} = 0.5\n",
    "#q_obj = {'Q':-1.15,'quant':'fix','ovfl':'wrap'} # try  'ovfl':'sat'\n",
    "\n",
    "fx_Q_l = fx.Fixed(q_obj)\n",
    "fx_Q_r = fx.Fixed(q_obj) \n",
    "\n",
    "# initialize arrays for audio samples\n",
    "samples_in = zeros(CHUNK*2, dtype=np_type) # stereo int16\n",
    "samples_out = zeros(CHUNK*2, dtype=float) # stereo float\n",
    "samples_l  = samples_r = zeros(CHUNK, dtype=np_type) # separate channels int16\n",
    "\n",
    "data_out = 'start'\n",
    "data = np.empty(10)\n",
    "\n",
    "while data_out:\n",
    "\n",
    "# read CHUNK stereo samples to string and convert to numpy array.\n",
    "# R / L samples are interleaved, each sample is 16 bit wide (dtype = np.int16)\n",
    "    samples_in = np.fromstring(wf.readframes(CHUNK), dtype=np_type)\n",
    "\n",
    "    # split interleaved data stream into R and L channel:\n",
    "    samples_l = samples_in[0::2]\n",
    "    samples_r = samples_in[1::2]\n",
    "    if len(samples_r) < 2:\n",
    "        break # break out of the while loop when out of data\n",
    "    # Check whether there was enough data for a full frame\n",
    "    if len(samples_r) < CHUNK: # check whether frame has full length\n",
    "        samples_out = samples_np = zeros(len(samples_in), dtype=float)\n",
    "#        samples_l = samples_r = zeros(len(samples_in)/2, dtype=np_type)\n",
    "\n",
    "# - Convert from 16 bit integer to floating point in the range -1 ... 1\n",
    "# - Quantize \n",
    "# - Construct interleaved data stream from R/L channel (still as floating point)\n",
    "    \n",
    "# Process L and R channel separately\n",
    "#    samples_out[0::2] = fx_Q_l.fix(samples_l/2**15)\n",
    "#    samples_out[1::2] = fx_Q_r.fix(samples_r/2**15)\n",
    "\n",
    "# Stereo signal processing: This only works for sample-by-sample operations,\n",
    "# not e.g. for filtering where consecutive samples have to be combined\n",
    "    samples_out = fx_Q_r.fix(samples_in / 2. **15)\n",
    "\n",
    "# Do explicit type casting to 16 bit and convert data back to string \n",
    "    data_out = np.chararray.tostring((samples_out * 2.**15).astype(np_type)) # convert back to string\n",
    "#    data_out = wf.readframes(CHUNK) # direct streaming without numpy\n",
    "data = np.concatenate(data, data_out)    \n",
    "\n",
    "display(Audio(data=data, rate=samp_rate))\n",
    "\n",
    "    #stream.write(data_out) # play audio by writing audio data to the stream (blocking)\n",
    "#stream.stop_stream() # pause audio stream\n",
    "#stream.close() # close audio stream\n",
    "\n",
    "#p.terminate() # close PyAudio & terminate PortAudio system\n",
    "print(\"Overflows: \", fx_Q_r.N_over)\n",
    "print(\"Closed audio stream!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
